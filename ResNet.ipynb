{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ResNet.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"LKbTaqRsorPS","colab_type":"text"},"source":["## Mount gdrive\n","\n"]},{"cell_type":"code","metadata":{"id":"P13GtMu7R692","colab_type":"code","outputId":"b78529f5-9878-444b-dfad-967ec2178950","executionInfo":{"status":"ok","timestamp":1570865602442,"user_tz":-540,"elapsed":16320,"user":{"displayName":"거니거니","photoUrl":"","userId":"16696796393874585002"}},"colab":{"base_uri":"https://localhost:8080/","height":142}},"source":["from google.colab import drive\n","drive.mount('/gdrive')\n","%cd /gdrive"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /gdrive\n","/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VLJYpIgxSHjE","colab_type":"code","outputId":"9d547868-bad2-46a6-f51b-06fc6846ac68","executionInfo":{"status":"ok","timestamp":1570865609978,"user_tz":-540,"elapsed":699,"user":{"displayName":"거니거니","photoUrl":"","userId":"16696796393874585002"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["cd /gdrive/My Drive/데이터구조"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/gdrive/My Drive/데이터구조\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PDhWiMzon34b","colab_type":"code","colab":{}},"source":["ls"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sXGdGGwNo3cn","colab_type":"text"},"source":["\n","\n","---\n","\n","## Import Modules"]},{"cell_type":"code","metadata":{"id":"ddIuZ25OSKtc","colab_type":"code","colab":{}},"source":["import cv2\n","import numpy as np\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from torch.utils.data.sampler import SubsetRandomSampler\n","\n","from torchvision import transforms, utils, datasets, models\n","\n","import random\n","import os\n","\n","from skimage import io, transform\n","\n","import pandas as pd"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rjCPOYjMo7Qk","colab_type":"text"},"source":["\n","\n","---\n","\n","## STEP 1: Loading Dataset"]},{"cell_type":"code","metadata":{"id":"LDSPqXIig96K","colab_type":"code","colab":{}},"source":["print('STEP 1: LOADING DATASET')\n","\n","data_transforms = {\n","    'train': transforms.Compose([\n","        transforms.Resize(224), \n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","    ]),\n","    'val': transforms.Compose([\n","        transforms.Resize(224),\n","        transforms.ToTensor(),\n","    ])\n","}\n","\n","data_dir = './dataset/'\n","train_dataset = datasets.ImageFolder(data_dir, data_transforms['train'])\n","valid_dataset = datasets.ImageFolder(data_dir, data_transforms['val'])\n","\n","num_train = int(len(train_dataset)*0.8)\n","\n","train_dataset, _ = torch.utils.data.random_split(train_dataset, [num_train, len(train_dataset)-num_train])\n","_, valid_dataset = torch.utils.data.random_split(valid_dataset, [num_train, len(valid_dataset)-num_train])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1MzmD_A9hHTa","colab_type":"code","colab":{}},"source":["print(\"The number of training images : \", len(train_dataset))\n","print(\"The number of validation images : \", len(valid_dataset))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XngEzDH0pEFP","colab_type":"text"},"source":["\n","\n","---\n","\n","## STEP 2: Making Dataset Iterable (data loader)"]},{"cell_type":"code","metadata":{"id":"b-kPEzCRhIjJ","colab_type":"code","colab":{}},"source":["print('STEP 2: MAKING DATASET ITERABLE')\n","\n","data_loaders = {'train': torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True),\n","                'val': torch.utils.data.DataLoader(valid_dataset, batch_size=4, shuffle=False)\n","               }\n","\n","\n","class_names = ['김규상', '김동언', '김성원', '김성준', '김성훈', '김정규', '김정운', '류성환', '박경채', '박진오', '배동건', '변상훈', '원동민', '유영진', '유한결', '윤다솔', '이도훈', '이성철', '이승현', '이정', '이정윤', '이찬', '임지성', '정건모', '정회영', '조성우', '조원호', '조한성', '홍원혁']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OP-zFnwVo5ol","colab_type":"code","colab":{}},"source":["def imshow(inp, title=None):\n","    \"\"\" Imshow for Tensor. \"\"\"\n","    #print(inp[0])\n","    inp = inp.numpy().transpose((1, 2, 0))\n","    inp = np.clip(inp, 0, 1)\n","    plt.imshow(inp)\n","    if title is not None:\n","        plt.title(title)\n","    plt.pause(0.001) # pause a bit so that plots are updated"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WV7VdGzco6sq","colab_type":"code","outputId":"0120c36e-4619-4c33-e344-236d52536e63","executionInfo":{"status":"error","timestamp":1584349416836,"user_tz":-540,"elapsed":1124,"user":{"displayName":"배동건","photoUrl":"","userId":"16696796393874585002"}},"colab":{"base_uri":"https://localhost:8080/","height":239}},"source":["fig = plt.figure()\n","\n","inputs, classes = next(iter(data_loaders['train']))\n","\n","out = utils.make_grid(inputs)\n","\n","imshow(out)"],"execution_count":0,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-2269c8fe8e89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"1nuguYGmpLJ9","colab_type":"text"},"source":["\n","\n","---\n","\n","## STEP 3: Create Model Class"]},{"cell_type":"code","metadata":{"id":"oPSQPIWIh4M4","colab_type":"code","colab":{}},"source":["print('STEP 3: CREATE MODEL CLASS')\n","\n","class ResNet(nn.Module):\n","    def __init__(self):\n","        super(ResNet, self).__init__()\n","        \n","        self.conv1 = models.resnet18(pretrained=True, progress=True).conv1\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","        self.layer1 = models.resnet18(pretrained=True, progress=True).layer1\n","        self.layer2 = models.resnet18(pretrained=True, progress=True).layer2\n","        self.layer3 = models.resnet18(pretrained=True, progress=True).layer3\n","        self.layer4 = models.resnet18(pretrained=True, progress=True).layer4\n","        self.avgpool = nn.AvgPool2d(7, stride=1)\n","        self.fc = nn.Linear(512, 30)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        x = self.maxpool(x)\n","\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","\n","        x = self.avgpool(x)\n","        x = x.view(x.size(0), -1)\n","        x = self.fc(x)\n","\n","        return x"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FxXkNmivpOPX","colab_type":"text"},"source":["\n","\n","---\n","\n","## STEP 4: Instantiate Model Class"]},{"cell_type":"code","metadata":{"id":"EW7JKt3kiR0W","colab_type":"code","colab":{}},"source":["print('STEP 4: INSTANTIATE MODEL CLASS')\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","model = ResNet().to(device)\n","i = 0\n","for name, param in model.named_parameters():\n","    #print(i, name) \n","    # Fine tune until layer 4[129], layer 3[72]\n","    if i < 45:\n","        param.requires_grad = False\n","        \n","    i += 1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RCL6OzSnlY9Q","colab_type":"code","colab":{}},"source":["for name, param in model.named_parameters():\n","    if param.requires_grad:\n","        print(name)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N1-vCu8dpSV-","colab_type":"text"},"source":["\n","\n","---\n","\n","## STEP 5 & 6: Instantiate Loss and Optimizer"]},{"cell_type":"code","metadata":{"id":"ogRFTla8oTde","colab_type":"code","colab":{}},"source":["print('STEP 5: INSTANTIATE LOSS CLASS')\n","\n","criterion = nn.CrossEntropyLoss()\n","\n","print('STEP 6: INSTANTIATE OPTIMIZER CLASS')\n","\n","learning_rate = 0.001\n","momentum = 0.9\n","\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum = 0.9)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mMzxNpYop20U","colab_type":"text"},"source":["\n","\n","---\n","\n","## STEP 7: Train the Model"]},{"cell_type":"code","metadata":{"id":"B3IPO83epjjc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":257},"outputId":"8aa87871-07b3-461a-d190-08ec53dccf6a","executionInfo":{"status":"error","timestamp":1586105328383,"user_tz":-540,"elapsed":1795,"user":{"displayName":"‍배동건(학부학생/공과대학 전기전자공학)","photoUrl":"","userId":"16696796393874585002"}}},"source":["import time\n","\n","print('STEP 7: TRAIN THE MODEL')\n","\n","num_epochs = 20\n","best_accuracy = 0\n","\n","for epoch in range(num_epochs):\n","    start_time = time.time()\n","    total_loss = 0\n","    iter = 0\n","    model.train()\n","    for i, (images, labels) in enumerate(data_loaders['train']):\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        # Forward pass to get output/logits\n","        outputs = model(images)\n","        \n","        # Calculate Loss: softmax --> cross entropy loss\n","        loss = criterion(outputs, labels)\n","\n","        # Getting gradients w.r.t. parameters\n","        loss.backward()\n","         \n","        # Getting Total Loss for Calculat Average Loss of each epochs\n","        total_loss += loss.item()\n","        iter += 1\n","        \n","        # Updating parameters\n","        optimizer.step()\n","        \n","        if i % 100 == 0 and i != 0:\n","            print(i,'/', len(data_loaders['train']))\n","    # Evalutae the time of each epochs.\n","    running_time = time.time() - start_time\n","    \n","    model.eval()\n","    # Calculate Accuracy         \n","    correct = 0\n","    total = 0\n","    # Iterate through test dataset\n","    for images, labels in data_loaders['val']:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        # Forward pass only to get logits/output\n","        outputs = model(images)\n","\n","        # Get predictions from the maximum value\n","        _, predicted = torch.max(outputs.data, 1)\n","\n","        # Total number of labels\n","        total += labels.size(0)\n","\n","        # Total correct predictions\n","        if torch.cuda.is_available():\n","            correct += (predicted.cpu() == labels.cpu()).sum()\n","        else:\n","            correct += (predicted == labels).sum()\n","\n","        accuracy = 100 * correct.item() / total\n","\n","    # Print Loss\n","    print('epoch: {}. Loss: {}. Accuracy: {}. Elapsed: {} sec'.format(epoch, total_loss/iter, accuracy, running_time))\n","    if accuracy > best_accuracy:\n","        best_accuracy = accuracy\n","        trained_weight = {'state_dict':model.state_dict()}\n","print('Best Accuracy : {}'.format(best_accuracy))"],"execution_count":1,"outputs":[{"output_type":"stream","text":["STEP 7: TRAIN THE MODEL\n"],"name":"stdout"},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-7d07e3643ba6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0miter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"fzIMZPlJp6b4","colab_type":"text"},"source":["\n","\n","---\n","\n","## STEP 8: Show Wrong Answers"]},{"cell_type":"code","metadata":{"id":"3mHXAJMJt50S","colab_type":"code","colab":{}},"source":["model.load_state_dict(trained_weight['state_dict'])\n","\n","model.eval()\n","\n","# files to be compared\n","correct = 0\n","total = 0\n","\n","softmax = nn.Softmax(dim=1)\n","# Iterate through test dataset\n","for images, labels in data_loaders['val']:\n","  \n","    images = images.to(device)\n","    #labels = labels.to(device)\n","\n","    # Forward pass only to get logits/output\n","    outputs = model(images)\n","\n","    # Get predictions from the maximum value\n","    _, predicted = torch.max(outputs.data, 1)\n","    prob, _ = torch.max(softmax(outputs).data, 1)\n","    fig = plt.figure()\n","\n","    out = utils.make_grid(images.cpu())\n","    imshow(out)\n","    print('Predict : {}'.format([class_names[x] for x in predicted.cpu().tolist()]))\n","    print('Probability : {}'.format(prob.tolist()))\n","    print('GT : {}'.format([class_names[x] for x in labels.cpu().tolist()]))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7Q_ldD_achSK","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}